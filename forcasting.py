import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib

# Import ML Libraries
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier
from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error, 
                             f1_score, accuracy_score, classification_report, confusion_matrix)
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
plt.style.use('ggplot')
pd.options.mode.chained_assignment = None

# ==========================================
# ‚öôÔ∏è CONFIGURATION
# ==========================================
DATA_FOLDER = 'cleaned_data'
MODEL_FOLDER = 'models'
os.makedirs(MODEL_FOLDER, exist_ok=True)

# ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
FILE_MAIN = 'cleaned_HomeC.csv'
FILE_VALID = 'cleaned_Energy_Validation.csv'
FILE_FORECAST = 'cleaned_UCI_Power.csv' 

# ==============================================================================
# üè† PART 1: Regression Analysis (‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÑ‡∏ü)
# Metrics: R2, MAE, MSE, RMSE
# ==============================================================================
def train_regression_model(filename):
    print("\n" + "="*60)
    print("üöÄ PART 1: Regression Model (Predicting Energy Amount)")
    print("="*60)

    path = os.path.join(DATA_FOLDER, filename)
    if not os.path.exists(path):
        print(f"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {path}")
        return None

    df = pd.read_csv(path, index_col=0, parse_dates=True)
    
    # Feature Engineering
    df['hour'] = df.index.hour
    df['day_of_week'] = df.index.dayofweek
    df['month'] = df.index.month
    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)

    # Features Selection
    target_col = next((c for c in ['use', 'House overall', 'mains'] if c in df.columns), df.columns[0])
    features = ['hour', 'day_of_week', 'month', 'is_weekend', 'temperature', 'humidity']
    valid_features = [c for c in features if c in df.columns]

    X = df[valid_features]
    y = df[target_col]

    # Split Data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train
    print("‚è≥ Training Random Forest Regressor...")
    model = RandomForestRegressor(n_estimators=100, max_depth=12, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)

    # Predict
    preds = model.predict(X_test)

    # --- üìä DATA SCIENCE METRICS (REGRESSION) ---
    r2 = r2_score(y_test, preds)
    mae = mean_absolute_error(y_test, preds)
    mse = mean_squared_error(y_test, preds)
    rmse = np.sqrt(mse)

    print(f"\nüèÜ Model Evaluation Results:")
    print(f"   1. R-Squared (R¬≤) : {r2:.4f}  (‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏Å‡∏•‡πâ 1 ‡∏¢‡∏¥‡πà‡∏á‡πÅ‡∏°‡πà‡∏ô)")
    print(f"   2. MAE            : {mae:.4f} kW (‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)")
    print(f"   3. RMSE           : {rmse:.4f} kW (Error ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ)")

    # Plot Actual vs Predicted
    plt.figure(figsize=(8, 6))
    plt.scatter(y_test, preds, alpha=0.3, color='blue')
    plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
    plt.xlabel('Actual Usage')
    plt.ylabel('Predicted Usage')
    plt.title(f'Regression Result: Actual vs Predicted (R2={r2:.2f})')
    plt.show() 
    
    # 

    return df  # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡πà‡∏≠

# ==============================================================================
# üö® PART 1.5: Classification Analysis (High Usage Detection)
# Metrics: F1-Score, Accuracy, Confusion Matrix
# ==============================================================================
def train_classification_model(df):
    print("\n" + "="*60)
    print("üö¶ PART 1.5: Classification Model (Detecting High Usage)")
    print("   (To calculate F1-Score, we transform this into a classification problem)")
    print("="*60)

    # 1. Create Classification Target (‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÉ‡∏´‡∏°‡πà)
    # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ + 1 Standard Deviation ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô "High Usage" (Class 1)
    target_col = next((c for c in ['use', 'House overall', 'mains'] if c in df.columns), df.columns[0])
    threshold = df[target_col].mean() + df[target_col].std()
    
    df['is_high_usage'] = (df[target_col] > threshold).astype(int)
    print(f"‚ÑπÔ∏è Threshold for High Usage: > {threshold:.2f} kW")
    print(f"‚ÑπÔ∏è Class Balance: {df['is_high_usage'].value_counts().to_dict()} (0=Normal, 1=High)")

    features = ['hour', 'day_of_week', 'month', 'temperature', 'humidity']
    valid_features = [c for c in features if c in df.columns]

    X = df[valid_features]
    y = df['is_high_usage']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train Classifier
    print("‚è≥ Training Random Forest Classifier...")
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train, y_train)

    # Predict
    y_pred = clf.predict(X_test)

    # --- üìä DATA SCIENCE METRICS (CLASSIFICATION) ---
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    print(f"\nüèÜ Classification Evaluation Results:")
    print(f"   1. Accuracy : {acc:.4f} (‡∏ó‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏Å‡∏µ‡πà %)")
    print(f"   2. F1-Score : {f1:.4f} (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ñ‡∏±‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ Precision/Recall)")
    print("\nüìã Detailed Classification Report:")
    print(classification_report(y_test, y_pred))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'High'], yticklabels=['Normal', 'High'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix: High Usage Detection')
    plt.show() 
    
    # [Image of confusion matrix]


# ==============================================================================
# üîÆ PART 3: Time-Series Forecasting (Corrected Version)
# ==============================================================================
def train_forecasting_model(filename):
    print("\n" + "="*60)
    print("üöÄ PART 3: Time-Series Forecasting (UCI Data)")
    print("="*60)
    
    path = os.path.join(DATA_FOLDER, filename)
    if not os.path.exists(path):
        print(f"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {path}")
        return

    print(f"üìÇ Loading: {filename}")

    # --- üõ†Ô∏è 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (Robust Loading) ---
    try:
        # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö Comma (,) ‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Clean
        df = pd.read_csv(path, sep=',', index_col=0, parse_dates=True, low_memory=False, na_values=['?', 'nan'])
        
        # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 1 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÉ‡∏ä‡πâ separator ‡∏ú‡∏¥‡∏î ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Semicolon (;)
        if df.shape[1] <= 1:
            print("‚ö†Ô∏è Warning: ‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Comma, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Semicolon (;)...")
            df = pd.read_csv(path, sep=';', index_col=0, parse_dates=True, low_memory=False, na_values=['?', 'nan'])

    except Exception as e:
        print(f"‚ùå Error loading CSV: {e}")
        return

    # --- üõ†Ô∏è 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ï‡πà‡∏≠ ---
    print(f"üìä Raw Data Shape: {df.shape}") # ‡∏î‡∏π‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö
    
    if df.empty:
        print("‚ùå Error: ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Empty DataFrame)")
        return

    # ‡∏•‡∏ö‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (dropna) ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏´‡∏°
    df.dropna(inplace=True)
    if df.empty:
        print("‚ùå Error: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏≤‡∏¢‡∏´‡∏°‡∏î‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏ö‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ Null ‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà)")
        return

    # --- üõ†Ô∏è 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Target Column ---
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (Global_active_power)
    target_col = 'Global_active_power'
    
    # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á (Case insensitive)
    if target_col not in df.columns:
        possible_cols = [c for c in df.columns if 'global' in c.lower() and 'active' in c.lower()]
        if possible_cols:
            target_col = possible_cols[0]
            print(f"‚ÑπÔ∏è Auto-detected target column: '{target_col}'")
        else:
            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏≠‡∏µ‡∏Å ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                target_col = numeric_cols[0]
                print(f"‚ö†Ô∏è Warning: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å‡πÅ‡∏ó‡∏ô: '{target_col}'")
            else:
                print(f"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô {df.columns}")
                return

    print(f"üéØ Target Column: {target_col}")

    # --- ‡∏™‡πà‡∏ß‡∏ô Feature Engineering ‡πÅ‡∏•‡∏∞ Modeling (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
    df_hourly = df[[target_col]].copy()
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏ß‡∏£‡πå (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏µ string ‡∏õ‡∏ô)
    df_hourly[target_col] = pd.to_numeric(df_hourly[target_col], errors='coerce')
    
    # Resample ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
    df_hourly = df_hourly.resample('H').mean().dropna()
    df_hourly.columns = ['y']
    
    # Lag Features
    for i in [1, 24, 168]: 
        df_hourly[f'lag_{i}'] = df_hourly['y'].shift(i)
    df_hourly.dropna(inplace=True)

    if df_hourly.empty:
         print("‚ùå Error: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Lag Features (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)")
         return

    X = df_hourly.drop('y', axis=1)
    y = df_hourly['y']

    # Split
    split = int(len(X) * 0.9)
    X_train, X_test = X.iloc[:split], X.iloc[split:]
    y_train, y_test = y.iloc[:split], y.iloc[split:]

    print("‚è≥ Training Gradient Boosting Model...")
    model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    # Metrics
    rmse = np.sqrt(mean_squared_error(y_test, preds))
    mae = mean_absolute_error(y_test, preds)
    r2 = r2_score(y_test, preds)

    print(f"\nüèÜ Forecasting Evaluation Results:")
    print(f"   1. RMSE     : {rmse:.4f} kW")
    print(f"   2. MAE      : {mae:.4f} kW")
    print(f"   3. R-Squared: {r2:.4f}")

    # Plot
    plt.figure(figsize=(12, 5))
    plot_len = min(168, len(y_test)) # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô error ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 168 ‡∏ä‡∏°.
    plt.plot(y_test.index[:plot_len], y_test.values[:plot_len], label='Actual', color='green')
    plt.plot(y_test.index[:plot_len], preds[:plot_len], label='Forecast', color='red', linestyle='--')
    plt.title('Time Series Forecasting: Actual vs Forecast (1 Week)')
    plt.legend()
    plt.show()


# ==============================================================================
# MAIN
# ==============================================================================
if __name__ == "__main__":
    # 1. Regression (R2, MAE, MSE)
    df_result = train_regression_model(FILE_MAIN)

    # 2. Classification (F1 Score, Accuracy) -> ‡πÉ‡∏ä‡πâ Data ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö Part 1
    if df_result is not None:
        train_classification_model(df_result)

    # 3. Forecasting
    train_forecasting_model(FILE_FORECAST)